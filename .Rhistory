for(i.tmp in 1:2){
x.res = cleanBigOverlapsQuery(x.res)
x.res = cutSmallOverlapsQuery(x.res)
}
colnames(x.res)
source('../pannagram/synteny_funcs.R')
x.res = x.res0
for(i.tmp in 1:2){
x.res = cleanBigOverlapsQuery(x.res)
x.res = cutSmallOverlapsQuery(x.res)
}
x.dir = setDir(x.res, base.len = base.len)
checkCorrespToGenome(x.dir, query.fas = acc.fas,
base.fas.fw = ref.fas,
base.fas.bw = ref.fas.rc)
x.res = x.res0
x.res = cleanBigOverlapsQuery(x.res)
x.dir = setDir(x.res, base.len = base.len)
checkCorrespToGenome(x.dir, query.fas = acc.fas,
base.fas.fw = ref.fas,
base.fas.bw = ref.fas.rc)
x.df = x.res
idx.cut = which(x.df$rm.len != 0)
idx.cut
irow = 343
adjustment <- x.df$rm.len[irow]
x.df[irow,]
adjustment <- x.df$rm.len[irow]  # sing says about "begin" or "end"
# adjustment.dir <- ifelse(x.df$dir[irow] == 0, adjustment, (-1) * adjustment)
n.symbols = abs(adjustment)
n.symbols
adjustment
seq = seq2nt(x.df$V8[irow])
aln.adjust = tail(which(seq != '-'), n=n.symbols)[1]
x.df$V8[irow] = substr(x.df$V8[irow], 1, (aln.adjust-1))
x.df$V9[irow] = substr(x.df$V9[irow], 1, (aln.adjust-1))
x.df[irow,]
1720501 1720658 1705247 1705402
s.q.cut = seq2nt(x.df$V9[irow])
adjustment.q = sum(s.q.cut != '-') - 1
adjustment.q
x.df$V2[irow] + adjustment.q
x.df = x.res
x.df[irow,]
char(x.df$V8)
nchar(x.df$V8)
nchar(x.df$V8[irow])
x.df[irow,]
1720501-1720658
# Adjust strings in the alignment
seq = seq2nt(x.df$V8[irow])
aln.adjust = tail(which(seq != '-'), n=n.symbols)[1]
x.df$V8[irow] = substr(x.df$V8[irow], 1, (aln.adjust-1))
x.df$V9[irow] = substr(x.df$V9[irow], 1, (aln.adjust-1))
s.q.cut = seq2nt(x.df$V8[irow])
adjustment.q = sum(s.q.cut != '-') - 1
adjustment.q
x.df$V2[irow] + adjustment.q
s.b.cut = seq2nt(x.df$V9[irow])
adjustment.b = sum(s.b.cut != '-') - 1
x.df$V4[irow] + adjustment.q * sign(0.5 - x.df$dir[irow])
adjustment.q * sign(0.5 - x.df$dir[irow])
s.b.cut = seq2nt(x.df$V9[irow])
adjustment.b = sum(s.b.cut != '-') - 1
x.df$V4[irow] + adjustment.b * sign(0.5 - x.df$dir[irow])
source('../pannagram/synteny_funcs.R')
setwd("~/Library/CloudStorage/OneDrive-Personal/vienn/pacbio/pannagram")
source('../pannagram/synteny_funcs.R')
x.res = x.res0
for(i.tmp in 1:2){
x.res = cleanBigOverlapsQuery(x.res)
x.res = cutSmallOverlapsQuery(x.res)
}
x.dir = setDir(x.res, base.len = base.len)
checkCorrespToGenome(x.dir, query.fas = acc.fas,
base.fas.fw = ref.fas,
base.fas.bw = ref.fas.rc)
# ----------
# Fill up and down
## Prepare
x.sk = x.sk[order(x.sk$V2),]  # because all alignment will be according to the sorted "query"
# Find positions of blocks, so that only at block edges somethings is changing, so we need not-trivial gaps
x.sk$bl.end <- c(diff(x.sk$block.id) != 0, 1)
x.sk$bl.beg <- c(1, diff(x.sk$block.id) != 0)
x.sk$idx = 1:nrow(x.sk)
y.tops = x.sk$p.beg  # top positions
y.bots = x.sk$p.end  # bottom positions
# Read blast results on "between blocks"
x.gap = read.table(paste(path.work, 'acc_', acc, '_qchr_', i.chr, '_bchr_', i.chr, '_residual_out.txt',
sep = ''),
stringsAsFactors = F)
# Get real positions of fragments
x.gap$q.beg = as.numeric(sapply(x.gap$V1, function(s) strsplit(s, '\\|')[[1]][2])) - 1
x.gap$b.beg = as.numeric(sapply(x.gap$V10, function(s) strsplit(s, '\\|')[[1]][2])) - 1
x.gap$V2 = x.gap$V2 + x.gap$q.beg
x.gap$V3 = x.gap$V3 + x.gap$q.beg
x.gap$V4 = x.gap$V4 + x.gap$b.beg
x.gap$V5 = x.gap$V5 + x.gap$b.beg
x.gap$idx = -(1:nrow(x.gap))
x.gap$dir = (x.gap$V4 > x.gap$V5) * 1  # BUT DON'T change the order of V4 and V5
x.gap$bl.beg = -1
x.gap$bl.end = -1
# Combine new core skeleton and new gaps
comb.names = intersect(colnames(x.sk), colnames(x.gap))
x.comb = rbind(x.sk[, comb.names],
x.gap[, comb.names])
x.comb = x.comb[order(x.comb$V2),]  # This sorting is relevant, because x.sk was initially also sorted!!
idx.end = which(x.comb$bl.end == 1)
idx.beg = which(x.comb$bl.beg == 1)
idx.remain = c()
for(i.cur in idx.end){
pokaz(i.cur)
# if(x.comb$dir[i.cur] == 1) next
n.gaps = countValueStretch(x.comb$bl.end, i.cur)
if(n.gaps == 0) next
# Get all possible BLAST-hits, which can be "after" the block.
x.tmp = x.comb[i.cur + (0:(n.gaps)),]
x.tmp$w = abs(x.tmp$V3 - x.tmp$V2) + abs(x.tmp$V4 - x.tmp$V5)
x.tmp$w[1] = 0
# # Remain the proper direction
# x.tmp = x.tmp[x.tmp$dir == x.tmp$dir[1],]
if(x.comb$dir[i.cur] == 0){
# Find next "top" base, so you should not consider BLAST-hits higher than this
y.top = min(c(Inf, y.tops[y.tops > x.comb$V5[i.cur]]))
y.bot = min(x.comb$V4[i.cur], x.comb$V5[i.cur])  # min - потому что хочу взять и саму затравку
x.tmp = x.tmp[(x.tmp$V4 >= y.bot) & (x.tmp$V5 >= y.bot),]
x.tmp = x.tmp[(x.tmp$V4 <= y.top) & (x.tmp$V5 <= y.top),]
if(nrow(x.tmp) <= 1) next
# Run path search
idx.visit = pathUpPlus(x.tmp)
} else {
# Find next "bottom" base, so you should not consider BLAST-hits higher than this
y.bot = max(c(-Inf, y.bots[y.bots < x.comb$V5[i.cur]]))
y.top = max(x.comb$V4[i.cur], x.comb$V5[i.cur])
x.tmp = x.tmp[(x.tmp$V4 >= y.bot) & (x.tmp$V5 >= y.bot),]
x.tmp = x.tmp[(x.tmp$V4 <= y.top) & (x.tmp$V5 <= y.top),]
if(nrow(x.tmp) <= 1) next
idx.visit = pathUpMinus(x.tmp)
}
# If found something - add
if(!is.null(idx.visit)){
idx.remain = c(idx.remain, x.tmp$idx[idx.visit][-1])
}
}
# ------------------------------------------------------------
# Downwards
for(i.cur in idx.beg){
# if(x.comb$dir[i.cur] == 1) next
n.gaps = countValueStretchBW(x.comb$bl.end, i.cur)
if(n.gaps == 0) next
# Get all possible BLAST-hits, which can be "after" the block.
x.tmp = x.comb[i.cur + ((-n.gaps):0),]
x.tmp$w = abs(x.tmp$V3 - x.tmp$V2) + abs(x.tmp$V4 - x.tmp$V5)
x.tmp$w[1] = 0
# # Remain the proper direction - NOT NEEDED, because I've changed to "top" and "bottom"
# x.tmp = x.tmp[x.tmp$dir == x.comb$dir[i.cur],]
if(x.comb$dir[i.cur] == 0){
# Find next "bottom" base, so you should not consider BLAST-hits higher than this
y.bot = max(c(-Inf, y.bots[y.bots < x.comb$V5[i.cur]]))
y.top = max(x.comb$V4[i.cur], x.comb$V5[i.cur])
x.tmp = x.tmp[(x.tmp$V4 >= y.bot) & (x.tmp$V5 >= y.bot),]
x.tmp = x.tmp[(x.tmp$V4 <= y.top) & (x.tmp$V5 <= y.top),]
if(nrow(x.tmp) <= 1) next
# Run path search
idx.visit = pathDownPlus(x.tmp)
} else {
# Find next "top" base, so you should not consider BLAST-hits higher than this
y.top = min(c(Inf, y.tops[y.tops > x.comb$V5[i.cur]]))
y.bot = min(x.comb$V4[i.cur], x.comb$V5[i.cur])  # min - потому что хочу взять и саму затравку
x.tmp = x.tmp[(x.tmp$V4 >= y.bot) & (x.tmp$V5 >= y.bot),]
x.tmp = x.tmp[(x.tmp$V4 <= y.top) & (x.tmp$V5 <= y.top),]
if(nrow(x.tmp) <= 1) next
# Run path search
idx.visit = pathDownMinus(x.tmp)
}
# If found something - add
if(!is.null(idx.visit)){
idx.remain = c(idx.remain, x.tmp$idx[idx.visit])
}
}
# plotDot(x.tmp)
# plotDot(x.tmp[idx.visit,])
#
# plotDot(x.comb[i.cur + (-12:5),])
#
# Remain "between" alignments
x.bw = x.gap[abs(idx.remain),]
# ---- Remove short overlaps: twice, because from "both sides" ----
for(i.tmp in 1:2){
x.bw = cleanBigOverlaps(x.bw)
x.bw = cutSmallOverlaps(x.bw)
}
for(i.tmp in 1:2){
x.bw = cleanBigOverlapsQuery(x.bw)
x.bw = cutSmallOverlapsQuery(x.bw)
}
# ---------
# Combine all together
comb.names = intersect(intersect(colnames(x.sk), colnames(x.bw)), colnames(x.res))
x.comb = rbind(x.res[,comb.names], x.sk[,comb.names])
x.comb = rbind(x.comb, x.bw[,comb.names])
x.comb = x.comb[order(x.comb$V2),]
rownames(x.comb) = NULL
x.dir = setDir(x.bw, base.len = base.len)
checkCorrespToGenome(x.dir, query.fas = acc.fas,
base.fas.fw = ref.fas,
base.fas.bw = ref.fas.rc)
rm(anna)
path.aln = '/Volumes/Samsung_T5/vienn/pannagram_test/aln/'
matching_files <- list.files(path = path.aln, pattern = "_1_.*full", full.names = TRUE)
path.aln = '/Volumes/Samsung_T5/vienn/pannagram_test/aln/'
matching_files <- list.files(path = path.aln, pattern = "_1_.*full", full.names = TRUE)
matching_files
matching_files <- list.files(path = path.aln, pattern = "_1_.*full")
matching_files
result <- sub("_(.*)", "", matching_files)
result
aln.files <- list.files(path = path.aln, pattern = ".*full")
aln.files
accessions <- unique(sub("_(.*)", "", aln.files))
accessions
acc = accessions
acc = accessions[1]
query.chr = i.chr
base.chr = i.chr
# pref.comb = paste0(query.name[i.query], '_', query.chr, '_', base.chr, collapse = '')
pref.comb = paste0(acc, '_', query.chr, '_', base.chr, collapse = '')
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
!file.exists(file.aln.full)
x = readRDS(file.aln.full)
base.len = 35000000
x.corr = getCorresp2BaseSign(x, base.len)
source('../pannagram/synteny_funcs.R')
x.corr = getCorresp2BaseSign(x, base.len)
getCorresp2BaseSign <- function(x, base.len){
pos.corresp = rep(0, base.len)
for(irow in 1:nrow(x)){
aln.len = nchar(x$V8[irow])
# Occupied positions in query
positions.q = rep(0, aln.len)
positions.q[seq2nt(x$V8[irow]) != '-'] = x$V2[irow]:x$V3[irow]
# Occupied positions in base
positions.b = rep(0, aln.len)
positions.b[seq2nt(x$V9[irow]) != '-'] = x$V4[irow]:x$V5[irow] * sign(0.5 - x$dir[irow])
positions.q = positions.q[positions.b != 0]
positions.b = positions.b[positions.b != 0]
pos.corresp[abs(positions.b)] = positions.q * sign(positions.b)
}
return(pos.corresp)
}
x.corr = getCorresp2BaseSign(x, base.len)
length(x.corr)
sum(x.corr > 0)
sum(x.corr != 0)
if (!requireNamespace("BiocManager", quietly=TRUE))
install.packages("BiocManager")
BiocManager::install("rhdf5")
library(rhdf5)
h5createFile(paste(path.common, 'comb_', query.chr, '_', base.chr,'.h5', sep = ''))
path.common = '/Volumes/Samsung_T5/vienn/pannagram_test/hdf5/'
h5createFile(paste(path.common, 'comb_', query.chr, '_', base.chr,'.h5', sep = ''))
H5close()
h5createFile(paste(path.common, 'comb_', query.chr, '_', base.chr,'.h5', sep = ''))
for(acc in accessions){
pokaz(acc)
# query.chr = chromosome.pairs[i.chr.pair, 2]
# base.chr = chromosome.pairs[i.chr.pair, 3]
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
if(!file.exists(file.aln.full)) next
x = readRDS(file.aln.full)
base.len = 35000000
x.corr = getCorresp2BaseSign(x, base.len)
# Путь внутри HDF5 файла для сохранения данных текущей итерации
group_path <- paste0("results/", acc)
# Если группа уже существует (для предыдущих итераций), удаляем ее
if(h5exists(group_path, "results.h5")) {
h5unlink(group_path, "results.h5")
}
# Записать данные текущей итерации в файл
h5write(x.corr, "results.h5", group_path)
}
H5close()
h5createFile(paste(path.common, 'comb_', query.chr, '_', base.chr,'.h5', sep = ''))
for(acc in accessions){
pokaz(acc)
# query.chr = chromosome.pairs[i.chr.pair, 2]
# base.chr = chromosome.pairs[i.chr.pair, 3]
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
if(!file.exists(file.aln.full)) next
x = readRDS(file.aln.full)
base.len = 35000000
x.corr = getCorresp2BaseSign(x, base.len)
# Путь внутри HDF5 файла для сохранения данных текущей итерации
group_path <- paste0("results/", acc)
# # Если группа уже существует (для предыдущих итераций), удаляем ее
# if(h5exists(group_path, "results.h5")) {
#     h5unlink(group_path, "results.h5")
# }
# Записать данные текущей итерации в файл
h5write(x.corr, "results.h5", group_path)
}
H5close()
file.comb = paste(path.common, 'comb_', query.chr, '_', base.chr,'.h5', sep = '')
h5createFile(file.comb)
for(acc in accessions){
pokaz(acc)
# query.chr = chromosome.pairs[i.chr.pair, 2]
# base.chr = chromosome.pairs[i.chr.pair, 3]
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
if(!file.exists(file.aln.full)) next
x = readRDS(file.aln.full)
base.len = 35000000
x.corr = getCorresp2BaseSign(x, base.len)
# Путь внутри HDF5 файла для сохранения данных текущей итерации
group_path <- paste0("results/", acc)
# # Если группа уже существует (для предыдущих итераций), удаляем ее
# if(h5exists(group_path, "results.h5")) {
#     h5unlink(group_path, "results.h5")
# }
# Записать данные текущей итерации в файл
h5write(x.corr, file.comb, group_path)
}
if (!h5exists("/results", file.comb)) {
h5createGroup(file.comb, "results")
}
h5createGroup(file.comb, "results")
h5createGroup(file.comb, "results")
h5write(x.corr, file.comb, group_path)
H5close()
h5createFile(file.comb)
for(acc in accessions){
pokaz(acc)
# query.chr = chromosome.pairs[i.chr.pair, 2]
# base.chr = chromosome.pairs[i.chr.pair, 3]
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
if(!file.exists(file.aln.full)) next
x = readRDS(file.aln.full)
base.len = 35000000
x.corr = getCorresp2BaseSign(x, base.len)
# Путь внутри HDF5 файла для сохранения данных текущей итерации
group_path <- paste0("results/", acc)
# Проверить наличие группы перед созданием
h5createGroup(file.comb, "results")
# Записать данные текущей итерации в файл
h5write(x.corr, file.comb, group_path)
}
H5close()
file_structure <- h5ls(file.comb)
file_structure
h5ls(file.comb)
file_structure[file_structure$type == "group", ]
base.len = 35000000
h5f = H5Fopen(file.comb)
h5f
h5f
H5close()
h5f = H5Fopen(file.comb)
h5f
h5createGroup(file.comb, "results")
h5closeAll()
h5createGroup(file.comb, "results")
h5ls("myhdf5file.h5")
h5ls(file.comb)
h5f = H5Fopen(file.comb)
h5f
h5f
h5f$results
length(h5f$results)
names(v)
names(h5f$results)
y = h5f$results['10001']
h5ls(file.comb)
h5closeAll()
h5ls(file.comb)
x = h5ls(file.comb)
x
x$otype
h5createFile(file.comb)
# Путь внутри HDF5 файла для сохранения данных текущей итерации
group_path <- paste0("results/", acc)
# Проверить наличие группы перед созданием
h5createGroup(file.comb, "results")
base.len = 35000000
for(acc in accessions){
pokaz(acc)
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
if(!file.exists(file.aln.full)) next
# Reading the alignment
x = readRDS(file.aln.full)
# Get query coordinates in base order
x.corr = getCorresp2BaseSign(x, base.len)
# Записать данные текущей итерации в файл
h5write(x.corr, file.comb, group_path)
}
H5close()
h5ls(file.comb)
h5.content = h5ls(file.comb)
h5.content
x.all = с()
x.all = c()
for(acc in accessions){
pokaz(acc)
file.aln.full <- paste(path.aln, paste0(pref.comb,  '_full.rds', collapse = ''), sep = '')
if(!file.exists(file.aln.full)) next
# Reading the alignment
x = readRDS(file.aln.full)
# Get query coordinates in base order
x.corr = getCorresp2BaseSign(x, base.len)
x.all = cbind(x.all, x.corr)
# Записать данные текущей итерации в файл
# h5write(x.corr, file.comb, group_path)
}
option_list = list(
make_option(c("--path.work"), type="character", default=NULL,
help="path to working directory", metavar="character"),
make_option(c("--path.base"), type="character", default=NULL,
help="path to base chromosomes", metavar="character"),
make_option(c("--path.aln.pref"), type="character", default=NULL,
help="path with alignments", metavar="character"),
make_option(c("--file.chr.len.ref"), type="character", default=NULL,
help="file with lengths of chromosomes of reference accessions", metavar="character"),
make_option(c("--n.cores"), type="character", default=NULL,
help="numer of cores: 10 max", metavar="character"),
make_option(c("--accs"), type="character", default=NULL,
help="accessions to create the alignment", metavar="character"),
make_option(c("--n.chr.ref"), type="character", default=NULL,
help="number of chromosomes in the reference genome", metavar="character"),
make_option(c("--n.chr.acc"), type="character", default=NULL,
help="number of chromosomes in the accessions", metavar="character"),
make_option(c("--ref.acc"), type="character", default=NULL,
help="reference accessions", metavar="character"),
make_option(c("--all.vs.all"), type="character", default=NULL,
help="alignment of all chromosomes vs all or not: T/F", metavar="character")
);
x = c(1,1,2,3,4)
x = cbind(x,x)
x
cbind(x, NA)
aln.suff = '_maj.rds'
sub("\\.rds$", "\\\\.rds$", aln.suff)
sub("\\.rds", "\\\\.rds$", aln.suff)
begs <- seq(1, base.len, by = chunk.len)
chunk.len = 100000
begs <- seq(1, base.len, by = chunk.len)
ends <- pmin(begs + chunk.len - 1, base.len)
ends
base.len = 35385723
chunk.len = 100000
begs <- seq(1, base.len, by = chunk.len)
ends <- pmin(begs + chunk.len - 1, base.len)
ends
begs
chunk.len = 100000
begs <- seq(1, base.len, by = chunk.len)
ends <- pmin(begs + chunk.len - 1, base.len)
df.chunks = data.frame(beg = begs, end = ends, chunk = paste('chunk', 1:length(begs), sep = '_'))
df.chunks
file.comb = paste(path.common, 'comb_', query.chr, '_', base.chr,'.h5', sep = '')
h5createFile(file.comb)
chunk.len = 100000
begs <- seq(1, base.len, by = chunk.len)
ends <- pmin(begs + chunk.len - 1, base.len)
df.chunks = data.frame(beg = begs, end = ends, chunk = paste('chunk', 1:length(begs), sep = '_'))
h5write(df.chunks, file.comb, 'chunks')
H5close()
h5.content = h5ls(file.comb)
h5.content
h5.content
h5f = H5Fopen(file.comb)
h5f[['chunks']]
h5f$chunks
index <- ceiling(seq_along(x.comb) / chunk.len)
index
x.comb
x.corr
indices <- ceiling(seq_along(x.corr) / chunk.len)
# Разделите вектор на фрагменты
chunks <- split(x.corr, indices)
z = readFastaMy('/Volumes/Samsung_T5/vienn/spider/DUM_chr_reform.fa')
names(z)
f01 = c(h0&s[[1]])
h5.content = h5ls(file.comb)
idx.beg <- which(idx.common == 1 & c(0, head(idx.common, -1)) == 0)
14 * 60 * 50
14 * 60 * 60 / 7 / 24
readFastaMy <- function(file.fasta){
start_time <- Sys.time()
file.content <- readLines(file.fasta)
header.idx <- c(which(substr(file.content, 1, 1) == ">"), length(file.content) + 1)
n.seq = length(header.idx) - 1
sequences <- c()
for(i.seq in 1:n.seq){
sequences = c(sequences,
paste0(file.content[(header.idx[i.seq]+1):(header.idx[i.seq+1]-1)], collapse = ''))
}
seq.names = file.content[header.idx[1:n.seq]]
seq.names = substr(seq.names, 2, nchar(seq.names))
names(sequences) = seq.names
rm(file.content)
return(sequences)
}
seqs = readFastaMy(paste(path.work, 'seq_pangen_cons_all.fasta', sep = ''))
path.work = '/Volumes/Samsung_T5/vienn/work_genomes/'
seqs = readFastaMy(paste(path.work, 'seq_pangen_cons_all.fasta', sep = ''))
names(seqs)
length(seqs[[1]])
seqs[1]
source('/Users/anna/Library/CloudStorage/OneDrive-Personal/vienn/pacbio/pannagram/utils.R')
sapply(seqs, function(s) length(seq2nt(s)))
df = data.frame(names = names(seqs), len = sapply(seqs, function(s) length(seq2nt(s))))
write.table(df, paste(path.work, 'pangen_chr_len.txt' ,sep = ''), col.names = F, row.names = F, quote = F, sep = '\t')
272 / 2
